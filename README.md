# Uni Stroke Gesture Recognizer

In this code base, we have implemented $1 gesture recognizer as a 5 part project. This algorithm can be used to detect 16 different types of uni stroke gestures with high level of accuracy. The working algorithm is implemented in part 3.

## Table of Contents

- [Introduction](#introduction)
- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
- [Contributing](#contributing)
- [License](#license)

## Introduction


This project implements the $1 Unistroke Gesture Recognizer as a comprehensive five-part series. It is designed to recognize 16 different unistroke gestures, providing a foundational tool for understanding user interface design, particularly how touch input is processed on screens. The $1 algorithm is pivotal in translating a userâ€™s simple gestures into actionable commands in software, demonstrating the crucial link between human input and computer understanding.

Our primary goal was to fully implement the $1 gesture recognizer, enabling it to accurately identify and replicate gestures using a set of predefined templates collected from various users. These templates serve as a baseline for recognizing future unistroke gestures drawn on a Tkinter-based interface. This project is particularly suited for developers, students, and researchers who are keen on developing human-centric applications and wish to delve deeper into the mechanics of gesture recognition technology. By participating in this project, contributors can expect to gain significant insights into the practical challenges and solutions in designing user-friendly interfaces that respond intuitively to touch.


## Features


This project offers a robust implementation of the $1 Unistroke Gesture Recognizer, structured as a comprehensive five-part series, each enhancing the system's capability and accuracy. Here are the key features that set this project apart:

Modular Design: Divided into five distinct parts, the project builds complexity incrementally, making it easy to understand and extend. Starting with a basic canvas using Tkinter, the project scales through various implementations of the gesture recognizer, culminating in a sophisticated gesture matching system.

Advanced Gesture Recognition: Initially implemented with a single template for each gesture, the recognizer's sophistication increases by incorporating multiple templates, significantly enhancing its accuracy and reliability across diverse user inputs.

Rich Dataset Collection: In the fourth stage, we collected multiple gesture templates from six different users, creating a rich dataset that reflects varied gestural inputs which are critical for improving recognition accuracy.

Data-Driven Improvements: The final part of the project leverages the collected data to refine gesture recognition. By comparing new input gestures against a comprehensive set of templates, the system achieves high precision in recognizing intended gestures.

Comparative Analysis: Utilizing heatmaps, we provide a visual comparative analysis between earlier and later stages of the project, illustrating the qualitative improvements in gesture recognition through our collected data and refined algorithms.

Ease of Use and High Accuracy: The interface is designed to be user-friendly, making it accessible for beginners and advanced users alike. The high accuracy of gesture recognition makes it an excellent tool for anyone interested in developing or studying human-centric applications.

These features not only demonstrate the technical depth of the project but also underscore its practical applications in enhancing user interface design through better gesture recognition technology.



## Installation

Follow these steps to get the project up and running on your system:

Clone the Repository:
Begin by cloning the GitHub repository to your local machine using the following command:

git clone https://github.com/username/repository.git

Install Dependencies:
This project requires Python's Tkinter library. Ensure you have Python installed on your system, then install Tkinter using pip:

pip install tk
Note: Tkinter typically comes pre-installed with Python. If you encounter any issues, check your Python installation.

Run the Application:
Navigate to the Part_3 -> Part_3_Sourcecode directory inside the cloned repository:

python canvas.py

Once the application is running, draw gestures such as a triangle, circle, or rectangle on the canvas, and the system will recognize them.
These steps will set up the $1 Unistroke Gesture Recognizer on your machine.

## Usage
You can also watch the demonstrations in the "Demonstrations" folder to understand how we implemented our project.

## Contributing

If you would like to contribute to the project, please feel free to clone the repository, make changes and raise a pull request. It would be really good if you could help with the implementation of the algorithms like $N Gesture Recognizer.

## License

MIT License. You are free to clone and distribute the code.

## Contact

- [Subhash Vadlamani, Veera Mattaparthi](vadlamanisubhash1998@gmail.com)
- [GitHub Repository](https://github.com/subhash-vadlamani/UniStrokeGestureRecognizer)

